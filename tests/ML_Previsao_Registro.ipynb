# ============================================================
# NOTEBOOK 2: MODELAGEM, TREINAMENTO E AVALIAÇÃO
# Dataset: Product Sentiment Classification
# Autor: Pedro Morato Lahoz
# ============================================================

# === CÉLULA 1: INSTALAÇÃO E IMPORTS ===
!pip install -q vaderSentiment transformers torch scikit-learn azure-ai-ml azure-identity

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                             f1_score, classification_report, confusion_matrix)
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import warnings
warnings.filterwarnings('ignore')

plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
%matplotlib inline

print("✅ Bibliotecas importadas!")

# === CÉLULA 2: CARREGAR DATASET TRATADO ===
print("📥 Carregando dataset tratado...")

df = pd.read_csv('dataset_tratado.csv')

print(f"✅ Dataset carregado!")
print(f"📊 Shape: {df.shape}")
print(f"📋 Colunas: {df.columns.tolist()}")

df.head()

# === CÉLULA 3: PREPARAÇÃO DOS DADOS ===
print("=" * 60)
print("🔧 PREPARAÇÃO PARA MODELAGEM")
print("=" * 60)

# Separar features e target
X = df['text_clean']
y = df['sentiment']

# Split treino/teste (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\n📊 Distribuição dos dados:")
print(f"   Treino: {len(X_train):,} ({len(X_train)/len(df)*100:.1f}%)")
print(f"   Teste:  {len(X_test):,} ({len(X_test)/len(df)*100:.1f}%)")

print(f"\n📈 Distribuição de classes (Treino):")
print(y_train.value_counts())
print(f"\n{(y_train.value_counts() / len(y_train) * 100).round(2)}")

# === CÉLULA 4: VETORIZAÇÃO TF-IDF ===
print("=" * 60)
print("🔢 VETORIZAÇÃO TF-IDF")
print("=" * 60)

print("\n⚙️  Criando vetorizador TF-IDF...")
vectorizer = TfidfVectorizer(
    max_features=5000,
    ngram_range=(1, 2),
    min_df=5,
    max_df=0.8
)

print("🔄 Transformando textos em vetores...")
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

print(f"\n✅ Vetorização concluída!")
print(f"   Shape treino: {X_train_tfidf.shape}")
print(f"   Shape teste:  {X_test_tfidf.shape}")
print(f"   Vocabulário:  {len(vectorizer.vocabulary_):,} palavras")

# === CÉLULA 5: MODELO 1 - VADER (Baseline) ===
print("=" * 60)
print("🤖 MODELO 1: VADER (Baseline)")
print("=" * 60)

analyzer = SentimentIntensityAnalyzer()

def vader_predict(text):
    """Prediz sentimento usando VADER"""
    scores = analyzer.polarity_scores(text)
    compound = scores['compound']
    
    if compound >= 0.05:
        return 'positive'
    elif compound <= -0.05:
        return 'negative'
    else:
        return 'neutral'

print("🔄 Fazendo predições com VADER...")
y_pred_vader = X_test.apply(vader_predict)

# Avaliar
acc_vader = accuracy_score(y_test, y_pred_vader)
print(f"\n✅ VADER - Acurácia: {acc_vader:.4f} ({acc_vader*100:.2f}%)")

print("\n📊 Relatório de Classificação:")
print(classification_report(y_test, y_pred_vader))

# === CÉLULA 6: MODELO 2 - NAIVE BAYES ===
print("=" * 60)
print("🤖 MODELO 2: NAIVE BAYES")
print("=" * 60)

print("⚙️  Treinando Multinomial Naive Bayes...")
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)

print("🔄 Fazendo predições...")
y_pred_nb = nb_model.predict(X_test_tfidf)

# Avaliar
acc_nb = accuracy_score(y_test, y_pred_nb)
print(f"\n✅ Naive Bayes - Acurácia: {acc_nb:.4f} ({acc_nb*100:.2f}%)")

print("\n📊 Relatório de Classificação:")
print(classification_report(y_test, y_pred_nb))

# === CÉLULA 7: MODELO 3 - LOGISTIC REGRESSION ===
print("=" * 60)
print("🤖 MODELO 3: LOGISTIC REGRESSION")
print("=" * 60)

print("⚙️  Treinando Logistic Regression...")
lr_model = LogisticRegression(max_iter=1000, random_state=42)
lr_model.fit(X_train_tfidf, y_train)

print("🔄 Fazendo predições...")
y_pred_lr = lr_model.predict(X_test_tfidf)

# Avaliar
acc_lr = accuracy_score(y_test, y_pred_lr)
print(f"\n✅ Logistic Regression - Acurácia: {acc_lr:.4f} ({acc_lr*100:.2f}%)")

print("\n📊 Relatório de Classificação:")
print(classification_report(y_test, y_pred_lr))

# === CÉLULA 8: MODELO 4 - RANDOM FOREST ===
print("=" * 60)
print("🤖 MODELO 4: RANDOM FOREST")
print("=" * 60)

print("⚙️  Treinando Random Forest...")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
rf_model.fit(X_train_tfidf, y_train)

print("🔄 Fazendo predições...")
y_pred_rf = rf_model.predict(X_test_tfidf)

# Avaliar
acc_rf = accuracy_score(y_test, y_pred_rf)
print(f"\n✅ Random Forest - Acurácia: {acc_rf:.4f} ({acc_rf*100:.2f}%)")

print("\n📊 Relatório de Classificação:")
print(classification_report(y_test, y_pred_rf))

# === CÉLULA 9: COMPARAÇÃO DE MODELOS ===
print("=" * 60)
print("📊 COMPARAÇÃO DE TODOS OS MODELOS")
print("=" * 60)

# Calcular métricas para todos
models = {
    'VADER': y_pred_vader,
    'Naive Bayes': y_pred_nb,
    'Logistic Regression': y_pred_lr,
    'Random Forest': y_pred_rf
}

results = []
for name, predictions in models.items():
    acc = accuracy_score(y_test, predictions)
    prec = precision_score(y_test, predictions, average='weighted', zero_division=0)
    rec = recall_score(y_test, predictions, average='weighted', zero_division=0)
    f1 = f1_score(y_test, predictions, average='weighted', zero_division=0)
    
    results.append({
        'Modelo': name,
        'Acurácia': acc,
        'Precision': prec,
        'Recall': rec,
        'F1-Score': f1
    })

results_df = pd.DataFrame(results)
results_df = results_df.sort_values('Acurácia', ascending=False)

print("\n📈 Tabela de Resultados:")
print(results_df.to_string(index=False))

# Visualizar
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

metrics = ['Acurácia', 'Precision', 'Recall', 'F1-Score']
colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12']

for idx, metric in enumerate(metrics):
    ax = axes[idx // 2, idx % 2]
    results_df.plot(x='Modelo', y=metric, kind='bar', ax=ax, 
                    color=colors[idx], legend=False)
    ax.set_title(f'{metric} por Modelo', fontsize=14, fontweight='bold')
    ax.set_ylabel(metric)
    ax.set_ylim([0, 1])
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')
    
    # Adicionar valores nas barras
    for container in ax.containers:
        ax.bar_label(container, fmt='%.3f')

plt.tight_layout()
plt.show()

# === CÉLULA 10: MATRIZES DE CONFUSÃO ===
print("=" * 60)
print("🎯 MATRIZES DE CONFUSÃO")
print("=" * 60)

fig, axes = plt.subplots(2, 2, figsize=(16, 14))

for idx, (name, predictions) in enumerate(models.items()):
    ax = axes[idx // 2, idx % 2]
    
    cm = confusion_matrix(y_test, predictions)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                xticklabels=sorted(y_test.unique()),
                yticklabels=sorted(y_test.unique()))
    ax.set_title(f'Matriz de Confusão - {name}', fontsize=12, fontweight='bold')
    ax.set_ylabel('Real')
    ax.set_xlabel('Predito')

plt.tight_layout()
plt.show()

# === CÉLULA 11: SELEÇÃO DO MELHOR MODELO ===
best_model_name = results_df.iloc[0]['Modelo']
best_accuracy = results_df.iloc[0]['Acurácia']

print("=" * 60)
print("🏆 MELHOR MODELO")
print("=" * 60)
print(f"\n✨ Modelo selecionado: {best_model_name}")
print(f"📈 Acurácia: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")

# Selecionar modelo treinado
if best_model_name == 'Naive Bayes':
    best_model = nb_model
elif best_model_name == 'Logistic Regression':
    best_model = lr_model
elif best_model_name == 'Random Forest':
    best_model = rf_model
else:
    best_model = None
    print("\n⚠️  VADER não precisa ser salvo (rule-based)")

# === CÉLULA 12: ANÁLISE DE ERROS ===
print("=" * 60)
print("🔍 ANÁLISE DE ERROS DO MELHOR MODELO")
print("=" * 60)

if best_model_name != 'VADER':
    y_pred_best = best_model.predict(X_test_tfidf)
else:
    y_pred_best = y_pred_vader

# Criar DataFrame com resultados
results_analysis = pd.DataFrame({
    'text': X_test.values,
    'real': y_test.values,
    'predicted': y_pred_best
})

results_analysis['correct'] = results_analysis['real'] == results_analysis['predicted']

# Exemplos de acertos
print("\n✅ EXEMPLOS DE ACERTOS:")
print("=" * 60)
correct_samples = results_analysis[results_analysis['correct']].sample(min(5, len(results_analysis[results_analysis['correct']])))
for idx, row in correct_samples.iterrows():
    print(f"\n📝 Texto: {row['text'][:100]}...")
    print(f"   Real: {row['real']} | Predito: {row['predicted']} ✓")

# Exemplos de erros
print("\n\n❌ EXEMPLOS DE ERROS:")
print("=" * 60)
error_samples = results_analysis[~results_analysis['correct']].sample(min(5, len(results_analysis[~results_analysis['correct']])))
for idx, row in error_samples.iterrows():
    print(f"\n📝 Texto: {row['text'][:100]}...")
    print(f"   Real: {row['real']} | Predito: {row['predicted']} ✗")

# Estatísticas de erros
error_rate = (~results_analysis['correct']).sum() / len(results_analysis) * 100
print(f"\n\n📊 Taxa de erro: {error_rate:.2f}%")
print(f"📊 Taxa de acerto: {100-error_rate:.2f}%")

# === CÉLULA 13: REGISTRAR MODELO NO AZURE ML ===
print("=" * 60)
print("☁️ REGISTRO DO MODELO NO AZURE ML")
print("=" * 60)

try:
    from azure.ai.ml import MLClient
    from azure.identity import DefaultAzureCredential
    from azure.ai.ml.entities import Model
    from azure.ai.ml.constants import AssetTypes
    import joblib
    import os
    
    # Configurar credenciais Azure
    print("\n🔐 Configurando credenciais Azure...")
    print("⚠️  Certifique-se de estar autenticado no Azure CLI")
    
    # Seus dados do Azure (SUBSTITUA com seus valores)
    SUBSCRIPTION_ID = "your-subscription-id"  # ← ALTERE AQUI
    RESOURCE_GROUP = "your-resource-group"    # ← ALTERE AQUI
    WORKSPACE_NAME = "your-workspace-name"    # ← ALTERE AQUI
    
    # Criar cliente ML
    credential = DefaultAzureCredential()
    ml_client = MLClient(
        credential=credential,
        subscription_id=SUBSCRIPTION_ID,
        resource_group_name=RESOURCE_GROUP,
        workspace_name=WORKSPACE_NAME
    )
    
    print(f"✅ Conectado ao workspace: {WORKSPACE_NAME}")
    
    # Salvar modelo localmente primeiro
    print("\n💾 Salvando modelo localmente...")
    model_dir = "./model"
    os.makedirs(model_dir, exist_ok=True)
    
    if best_model_name != 'VADER':
        # Salvar modelo ML
        joblib.dump(best_model, f"{model_dir}/model.pkl")
        joblib.dump(vectorizer, f"{model_dir}/vectorizer.pkl")
        print(f"   ✅ Modelo salvo: {model_dir}/model.pkl")
        print(f"   ✅ Vectorizer salvo: {model_dir}/vectorizer.pkl")
        
        # Salvar informações do modelo
        model_info = {
            'model_name': best_model_name,
            'accuracy': float(best_accuracy),
            'features': X_train_tfidf.shape[1],
            'classes': list(y_train.unique())
        }
        import json
        with open(f"{model_dir}/model_info.json", 'w') as f:
            json.dump(model_info, f, indent=2)
        print(f"   ✅ Info salva: {model_dir}/model_info.json")
    
    # Registrar no Azure ML
    print("\n☁️  Registrando modelo no Azure ML...")
    
    model = Model(
        path=model_dir,
        type=AssetTypes.CUSTOM_MODEL,
        name=f"sentiment-analysis-{best_model_name.lower().replace(' ', '-')}",
        description=f"Modelo de análise de sentimentos usando {best_model_name}",
        tags={
            "model_type": best_model_name,
            "accuracy": str(best_accuracy),
            "framework": "scikit-learn",
            "task": "sentiment-analysis"
        }
    )
    
    registered_model = ml_client.models.create_or_update(model)
    
    print(f"\n✅ Modelo registrado no Azure ML!")
    print(f"   📦 Nome: {registered_model.name}")
    print(f"   🔢 Versão: {registered_model.version}")
    print(f"   📊 Acurácia: {best_accuracy:.4f}")
    
except ImportError:
    print("\n⚠️  Bibliotecas Azure não instaladas")
    print("   Execute: pip install azure-ai-ml azure-identity")
    print("\n💾 Salvando modelo localmente apenas...")
    
    import joblib
    import os
    
    model_dir = "./model"
    os.makedirs(model_dir, exist_ok=True)
    
    if best_model_name != 'VADER':
        joblib.dump(best_model, f"{model_dir}/model.pkl")
        joblib.dump(vectorizer, f"{model_dir}/vectorizer.pkl")
        print(f"   ✅ Modelo salvo: {model_dir}/model.pkl")
        print(f"   ✅ Vectorizer salvo: {model_dir}/vectorizer.pkl")
    
except Exception as e:
    print(f"\n❌ Erro ao registrar no Azure: {str(e)}")
    print("\n💾 Salvando modelo localmente apenas...")
    
    import joblib
    import os
    
    model_dir = "./model"
    os.makedirs(model_dir, exist_ok=True)
    
    if best_model_name != 'VADER':
        joblib.dump(best_model, f"{model_dir}/model.pkl")
        joblib.dump(vectorizer, f"{model_dir}/vectorizer.pkl")
        print(f"   ✅ Modelo salvo: {model_dir}/model.pkl")

# === CÉLULA 14: FUNÇÃO DE PREDIÇÃO ===
print("=" * 60)
print("🎯 CRIANDO FUNÇÃO DE PREDIÇÃO")
print("=" * 60)

def predict_sentiment(text, model_name=best_model_name):
    """
    Prediz sentimento de um texto
    
    Args:
        text (str): Texto para análise
        model_name (str): Nome do modelo a usar
    
    Returns:
        dict: Resultado com sentimento e confiança
    """
    # Limpar texto
    text_clean = text.lower()
    text_clean = re.sub(r'http\S+', '', text_clean)
    text_clean = re.sub(r'[^a-z\s]', '', text_clean)
    text_clean = ' '.join(text_clean.split())
    
    if model_name == 'VADER':
        scores = analyzer.polarity_scores(text_clean)
        compound = scores['compound']
        
        if compound >= 0.05:
            sentiment = 'positive'
        elif compound <= -0.05:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'
        
        confidence = abs(compound)
        
    else:
        # Vetorizar
        text_vec = vectorizer.transform([text_clean])
        
        # Predição
        sentiment = best_model.predict(text_vec)[0]
        
        # Confiança (probabilidade)
        if hasattr(best_model, 'predict_proba'):
            probs = best_model.predict_proba(text_vec)[0]
            confidence = max(probs)
        else:
            confidence = 1.0
    
    return {
        'text': text,
        'sentiment': sentiment,
        'confidence': confidence,
        'model': model_name
    }

print("\n✅ Função de predição criada!")

# === CÉLULA 15: TESTAR MODELO ===
print("=" * 60)
print("🧪 TESTANDO MODELO COM EXEMPLOS")
print("=" * 60)

test_examples = [
    "This product is amazing! I love it so much!",
    "Terrible quality. Waste of money. Very disappointed.",
    "It's okay, nothing special but does the job.",
    "Best purchase ever! Highly recommend to everyone!",
    "Horrible experience. Would not buy again."
]

print(f"\n🤖 Modelo: {best_model_name}\n")

for text in test_examples:
    result = predict_sentiment(text)
    
    emoji = "😊" if result['sentiment'] == 'positive' else "😞" if result['sentiment'] == 'negative' else "😐"
    
    print(f"\n{'='*60}")
    print(f"📝 Texto: {text}")
    print(f"{emoji} Sentimento: {result['sentiment'].upper()}")
    print(f"📊 Confiança: {result['confidence']:.2%}")

# === CÉLULA 16: ANÁLISE DE IMPORTÂNCIA DE FEATURES ===
if best_model_name in ['Logistic Regression', 'Random Forest']:
    print("\n" + "=" * 60)
    print("🔍 ANÁLISE DE IMPORTÂNCIA DE FEATURES")
    print("=" * 60)
    
    feature_names = vectorizer.get_feature_names_out()
    
    if best_model_name == 'Logistic Regression':
        # Para cada classe
        for idx, sentiment in enumerate(best_model.classes_):
            print(f"\n📊 Top 15 palavras para '{sentiment}':")
            coefficients = best_model.coef_[idx]
            top_indices = coefficients.argsort()[-15:][::-1]
            
            for i in top_indices:
                print(f"   {feature_names[i]:20s}: {coefficients[i]:.4f}")
    
    elif best_model_name == 'Random Forest':
        print("\n📊 Top 20 features mais importantes:")
        importances = best_model.feature_importances_
        top_indices = importances.argsort()[-20:][::-1]
        
        for i in top_indices:
            print(f"   {feature_names[i]:20s}: {importances[i]:.6f}")
        
        # Visualizar
        plt.figure(figsize=(12, 6))
        top_features = [(feature_names[i], importances[i]) for i in top_indices[:15]]
        features, values = zip(*top_features)
        plt.barh(features, values, color='skyblue')
        plt.xlabel('Importância')
        plt.title('Top 15 Features Mais Importantes', fontsize=14, fontweight='bold')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.show()

# === CÉLULA 17: CRIAR SCRIPT DE INFERÊNCIA ===
print("=" * 60)
print("📝 CRIANDO SCRIPT DE INFERÊNCIA")
print("=" * 60)

inference_script = f'''
import joblib
import re

# Carregar modelo e vectorizer
model = joblib.load('model/model.pkl')
vectorizer = joblib.load('model/vectorizer.pkl')

def predict(text):
    """Prediz sentimento de um texto"""
    # Limpar texto
    text_clean = text.lower()
    text_clean = re.sub(r'http\\S+', '', text_clean)
    text_clean = re.sub(r'[^a-z\\s]', '', text_clean)
    text_clean = ' '.join(text_clean.split())
    
    # Vetorizar
    text_vec = vectorizer.transform([text_clean])
    
    # Predição
    sentiment = model.predict(text_vec)[0]
    
    # Confiança
    if hasattr(model, 'predict_proba'):
        probs = model.predict_proba(text_vec)[0]
        confidence = max(probs)
    else:
        confidence = 1.0
    
    return {{
        'sentiment': sentiment,
        'confidence': float(confidence)
    }}

# Exemplo de uso
if __name__ == "__main__":
    text = "This product is amazing!"
    result = predict(text)
    print(f"Text: {{text}}")
    print(f"Sentiment: {{result['sentiment']}}")
    print(f"Confidence: {{result['confidence']:.2%}}")
'''

with open('inference.py', 'w') as f:
    f.write(inference_script)

print("\n✅ Script de inferência criado: inference.py")

# === CÉLULA 18: CONCLUSÕES E PRÓXIMOS PASSOS ===
print("\n" + "=" * 60)
print("📝 CONCLUSÕES DO PROJETO")
print("=" * 60)

print(f"""
✅ RESUMO DO PROJETO:

1️⃣  DATASET:
   • {len(df):,} reviews processadas
   • 3 classes de sentimento (positive, negative, neutral)
   • Dataset limpo e balanceado

2️⃣  MODELOS TESTADOS:
   • VADER (Baseline)
   • Naive Bayes
   • Logistic Regression
   • Random Forest

3️⃣  MELHOR MODELO:
   • 🏆 {best_model_name}
   • 📈 Acurácia: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)
   • ✅ Modelo salvo e registrado

4️⃣  RESULTADOS:
""")

print(results_df.to_string(index=False))

print(f"""

5️⃣  ARQUIVOS GERADOS:
   • ✅ dataset_tratado.csv - Dataset limpo
   • ✅ model/model.pkl - Modelo treinado
   • ✅ model/vectorizer.pkl - Vectorizer TF-IDF
   • ✅ inference.py - Script de inferência
   • ✅ Modelo registrado no Azure ML (se configurado)

🎯 PRÓXIMOS PASSOS:

1️⃣  MELHORIAS:
   • Testar BERT/RoBERTa para comparação
   • Implementar ensemble de modelos
   • Fine-tuning de hiperparâmetros
   • Aumentar dataset com data augmentation

2️⃣  DEPLOYMENT:
   • Criar API Flask/FastAPI
   • Deploy no Azure App Service
   • Monitoramento de performance
   • A/B testing

3️⃣  FEATURES ADICIONAIS:
   • Análise de aspectos (aspect-based sentiment)
   • Detecção de sarcasmo
   • Suporte multi-idioma
   • Análise de emoções (além de sentimentos)

💡 APRENDIZADOS:

✓ Pipeline completo de ML (EDA → Modelagem → Deploy)
✓ Comparação de múltiplos modelos
✓ Registro e versionamento de modelos
✓ Boas práticas de ML Engineering
✓ Integração com Azure ML

""")

print("=" * 60)
print("🎉 PROJETO CONCLUÍDO COM SUCESSO!")
print("=" * 60)

# === CÉLULA 19: MÉTRICAS FINAIS PARA RELATÓRIO ===
print("\n📊 MÉTRICAS FINAIS PARA RELATÓRIO:\n")

final_metrics = {
    'Dataset Original': initial_size,
    'Dataset Tratado': len(df),
    'Taxa de Retenção': f"{len(df)/initial_size*100:.2f}%",
    'Features (TF-IDF)': X_train_tfidf.shape[1],
    'Treino/Teste Split': '80/20',
    'Melhor Modelo': best_model_name,
    'Acurácia Final': f"{best_accuracy:.4f} ({best_accuracy*100:.2f}%)",
    'Precision (weighted)': f"{results_df.iloc[0]['Precision']:.4f}",
    'Recall (weighted)': f"{results_df.iloc[0]['Recall']:.4f}",
    'F1-Score (weighted)': f"{results_df.iloc[0]['F1-Score']:.4f}"
}

for key, value in final_metrics.items():
    print(f"   {key:25s}: {value}")

print("\n" + "=" * 60)
print("✅ NOTEBOOKS COMPLETOS - PRONTO PARA ENTREGA!")
print("=" * 60)