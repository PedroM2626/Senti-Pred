{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "37fce550",
      "metadata": {
        "id": "37fce550"
      },
      "source": [
        "# Senti-Pred: Pipeline Completo de Análise de Sentimentos\n",
        "## Autor: Pedro Morato Lahoz\n",
        "\n",
        "---\n",
        "\n",
        "### Índice:\n",
        "1. [Configuração Inicial](#config)\n",
        "2. [Análise Exploratória (EDA)](#eda)\n",
        "3. [Pré-processamento](#preprocessing)\n",
        "4. [Modelagem](#modeling)\n",
        "5. [Visualizações Comparativas](#visualizations)\n",
        "6. [Deploy com Docker](#deploy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8da4daa6",
      "metadata": {
        "id": "8da4daa6"
      },
      "source": [
        "---\n",
        "## 1. Configuração Inicial <a id='config'></a>\n",
        "\n",
        "(Se estiver usando Colab, execute a célula de setup em seguida.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f60f63b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f60f63b",
        "outputId": "f8fa34bf-38cb-45ae-d030-37baf2aee4f1"
      },
      "outputs": [],
      "source": [
        "# Setup para Google Colab (executar somente no Colab)\n",
        "# Detecta ambiente Colab, clona repo e instala dependências.\n",
        "import sys, os  # sys para detectar módulos (Colab), os para manipulação de caminhos\n",
        "from pathlib import Path  # Path para manipulação robusta de paths\n",
        "IN_COLAB = 'google.colab' in sys.modules  # True em Colab\n",
        "REPO = 'PedroM2626/Senti-Pred'  # repo para clonar se necessário\n",
        "CLONE_DIR = Path('/content/Senti-Pred')\n",
        "\n",
        "if IN_COLAB:\n",
        "    if not CLONE_DIR.exists():\n",
        "        print('Clonando repositorio para /content/Senti-Pred...')\n",
        "        get_ipython().system(f'git clone https://github.com/{REPO}.git {CLONE_DIR}')\n",
        "    %cd /content/Senti-Pred\n",
        "    print('Instalando dependencias... (pode demorar)')\n",
        "    # pip install -r requirements.txt para garantir libs corretas\n",
        "    get_ipython().system('pip install -q -r requirements.txt || true')\n",
        "else:\n",
        "    print('Nao detectado Colab; assumindo execucao local. Verifique dependencias manualmente.')\n",
        "\n",
        "# criar diretórios usados pelo notebook\n",
        "os.makedirs('data/raw', exist_ok=True)\n",
        "os.makedirs('reports/visualizacoes', exist_ok=True)\n",
        "os.makedirs('reports/metrics', exist_ok=True)\n",
        "os.makedirs('src/models', exist_ok=True)\n",
        "\n",
        "# baixar recursos NLTK de forma silenciosa (pode já estar instalado)\n",
        "import nltk  # biblioteca de processamento de linguagem natural\n",
        "for r in ['punkt','stopwords','wordnet','omw-1.4','averaged_perceptron_tagger']:\n",
        "    try:\n",
        "        nltk.download(r, quiet=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "print('Setup concluido. IN_COLAB =', IN_COLAB)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9221653",
      "metadata": {
        "id": "b9221653"
      },
      "source": [
        "---\n",
        "## Imports e Configuração Inicial\n",
        "\n",
        "Aqui importamos todas as bibliotecas necessárias. Cada import tem um comentário curto explicando por que está sendo usado no pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ffc067",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8ffc067",
        "outputId": "4c600a8d-87dd-42bb-f511-e4a63a9e1d21"
      },
      "outputs": [],
      "source": [
        "# Imports com comentarios explicativos\n",
        "import os  # manipulação de caminhos, criação de pastas, checagens de arquivos\n",
        "import re  # regex para limpeza de texto (URLs, menções, caracteres especiais)\n",
        "import json  # salvar/ler metadados e metricas em formato JSON\n",
        "import time  # medir tempos de treino/inferencia\n",
        "import warnings  # silenciar avisos não-críticos durante o notebook\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import joblib  # salvar/carregar pipelines e modelos de forma eficiente\n",
        "import numpy as np  # operações numéricas e manipulação de arrays\n",
        "import pandas as pd  # leitura de CSVs e manipulação de dataframes\n",
        "import matplotlib.pyplot as plt  # plotagem estática de gráficos\n",
        "import seaborn as sns  # visualizações estatísticas (heatmaps, estilo)\n",
        "from pathlib import Path  # objetos Path para manipulação de caminhos com segurança\n",
        "sns.set(style='whitegrid')  # estilo padrão para os plots\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Determinacao robusta de BASE_DIR (funciona em scripts e notebooks/Colab)\n",
        "try:\n",
        "    BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
        "except Exception:\n",
        "    # se __file__ nao existe (notebook), tentamos usar o path clonado no Colab\n",
        "    if 'IN_COLAB' in globals() and IN_COLAB:\n",
        "        candidate = Path('/content/Senti-Pred')\n",
        "        if candidate.exists():\n",
        "            BASE_DIR = str(candidate.resolve())\n",
        "        else:\n",
        "            BASE_DIR = str(Path.cwd())\n",
        "    else:\n",
        "        BASE_DIR = os.path.abspath(os.getcwd())\n",
        "\n",
        "# Caminhos utilizados no notebook (padronizados)\n",
        "TRAIN_RAW = os.path.join(BASE_DIR, 'data', 'raw', 'twitter_training.csv')\n",
        "VAL_RAW = os.path.join(BASE_DIR, 'data', 'raw', 'twitter_validation.csv')\n",
        "VIS_DIR = os.path.join(BASE_DIR, 'reports', 'visualizacoes')\n",
        "METRICS_DIR = os.path.join(BASE_DIR, 'reports', 'metrics')\n",
        "MODEL_PATH = os.path.join(BASE_DIR, 'src', 'models', 'sentiment_model.pkl')\n",
        "os.makedirs(VIS_DIR, exist_ok=True)\n",
        "os.makedirs(METRICS_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
        "\n",
        "print('[OK] Config inicial pronta — BASE_DIR:', BASE_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07be8a1f",
      "metadata": {
        "id": "07be8a1f"
      },
      "source": [
        "---\n",
        "## 2. Análise Exploratória (EDA) <a id='eda'></a>\n",
        "\n",
        "Nesta seção: carregar os CSVs brutos, inspecionar tamanhos, e salvar plots (gráficos) resumidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e6c2f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53e6c2f2",
        "outputId": "07f20860-cc21-4491-cf9e-0a8c3bf941e2"
      },
      "outputs": [],
      "source": [
        "# EDA: carregar dados e gerar graficos\n",
        "# Definimos nomes de colunas esperados (os CSVs originais podem nao conter header)\n",
        "cols = ['tweet_id','entity','sentiment','text']\n",
        "# Verificacao de existencia dos arquivos brutos - evita falhas silenciosas\n",
        "if not os.path.exists(TRAIN_RAW) or not os.path.exists(VAL_RAW):\n",
        "    raise FileNotFoundError(f'Esperado arquivos em {TRAIN_RAW} e {VAL_RAW} — coloque os CSVs em data/raw/')\n",
        "# Leitura com parametros robustos (encoding e engine)\n",
        "df_train = pd.read_csv(TRAIN_RAW, names=cols, header=None, engine='python', encoding='utf-8')\n",
        "df_val = pd.read_csv(VAL_RAW, names=cols, header=None, engine='python', encoding='utf-8')\n",
        "# Marcamos o split para uniao posterior se necessario\n",
        "df_train['split'] = 'train'\n",
        "df_val['split'] = 'validation'\n",
        "df = pd.concat([df_train, df_val], ignore_index=True)\n",
        "print(f'Dados carregados: train={len(df_train)} | validation={len(df_val)} | total={len(df)}')\n",
        "# Calculamos o comprimento dos textos (em palavras) para inspecionar a distribuicao\n",
        "df['text_length'] = df['text'].astype(str).apply(lambda s: len(s.split()))\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df['text_length'], bins=40, kde=True)\n",
        "plt.title('Distribuicao de comprimento de texto')\n",
        "plt.xlabel('Numero de palavras')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(VIS_DIR, 'text_length.png'))\n",
        "plt.close()\n",
        "# Top words: conteudo bruto (sem limpeza) — util para entender ruído e tokens frequentes\n",
        "all_words = ' '.join(df['text'].astype(str)).lower().split()\n",
        "top_raw = pd.Series(all_words).value_counts().head(20)\n",
        "plt.figure(figsize=(12,5))\n",
        "top_raw.plot(kind='bar')\n",
        "plt.title('Top words (raw)')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(VIS_DIR, 'top_words_raw.png'))\n",
        "plt.close()\n",
        "print('[OK] EDA: graficos salvos em reports/visualizacoes')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc04b426",
      "metadata": {
        "id": "bc04b426"
      },
      "source": [
        "---\n",
        "## 3. Pré-processamento <a id='preprocessing'></a>\n",
        "\n",
        "As funções abaixo realizam: limpeza básica (remoção de URLs/menções/caracteres), remoção de stopwords (palavras carregam pouco ou nenhum significado semântico relevante para a análise do conteúdo principal de um texto) em inglês, e lematização (palavras na sua forma base) usando POS-tagging (categoriza as palavras em suas respectivas classes gramaticais) para melhorar a normalização das palavras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2ae6173",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2ae6173",
        "outputId": "80152537-0eeb-4259-c3b5-73d7e9fa0625"
      },
      "outputs": [],
      "source": [
        "# Imports específicos para NLP com explicacoes\n",
        "from nltk.corpus import stopwords, wordnet  # stopwords para filtro; wordnet para mapear POS em lematizacao\n",
        "from nltk.stem import WordNetLemmatizer  # lematizador baseado em WordNet\n",
        "from nltk.tokenize import word_tokenize  # tokenizacao que lida com pontuacao/contracoes\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    # Limpeza: lowercase, remove urls, mentions, hashtags, pontuacao e digitos\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def remove_stopwords_en(text):\n",
        "    # Remove stopwords em ingles (usa tokenizacao do NLTK)\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text, language='english')\n",
        "    filtered = [w for w in tokens if w.lower() not in stop_words]\n",
        "    return ' '.join(filtered)\n",
        "\n",
        "def lemmatize_text_en(text):\n",
        "    # Lematizacao com POS para melhor precisão (adjetivos, verbos, substantivos, advérbios)\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    tokens = word_tokenize(text, language='english')\n",
        "    try:\n",
        "        pos_tags = nltk.pos_tag(tokens)\n",
        "    except Exception:\n",
        "        pos_tags = [(t, '') for t in tokens]\n",
        "    def _get_wordnet_pos(tag):\n",
        "        if tag.startswith('J'):\n",
        "            return wordnet.ADJ\n",
        "        if tag.startswith('V'):\n",
        "            return wordnet.VERB\n",
        "        if tag.startswith('N'):\n",
        "            return wordnet.NOUN\n",
        "        if tag.startswith('R'):\n",
        "            return wordnet.ADV\n",
        "        return wordnet.NOUN\n",
        "    lemmas = []\n",
        "    for token, tag in pos_tags:\n",
        "        wn_tag = _get_wordnet_pos(tag) if tag else wordnet.NOUN\n",
        "        lemmas.append(lemmatizer.lemmatize(token, wn_tag))\n",
        "    return ' '.join(lemmas)\n",
        "\n",
        "# Aplicacao das funcoes aos datasets (cria colunas intermediarias)\n",
        "df_train_proc = df_train.copy()\n",
        "df_val_proc = df_val.copy()\n",
        "df_train_proc['text_clean'] = df_train_proc['text'].apply(clean_text)\n",
        "df_train_proc['text_no_stop'] = df_train_proc['text_clean'].apply(remove_stopwords_en)\n",
        "df_train_proc['text_lemmatized'] = df_train_proc['text_no_stop'].apply(lemmatize_text_en)\n",
        "df_val_proc['text_clean'] = df_val_proc['text'].apply(clean_text)\n",
        "df_val_proc['text_no_stop'] = df_val_proc['text_clean'].apply(remove_stopwords_en)\n",
        "df_val_proc['text_lemmatized'] = df_val_proc['text_no_stop'].apply(lemmatize_text_en)\n",
        "print('[OK] Pre-processamento aplicado (dados em memoria)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66947b48",
      "metadata": {
        "id": "66947b48"
      },
      "source": [
        "---\n",
        "## 4. Modelagem <a id='modeling'></a>\n",
        "\n",
        "Treinamos 3 classificadores usando um pipeline TF-IDF (ajuda a identificar as palavras-chave mais importantes de um texto) + classificador. Cada passo tem comentário explicando a escolha de parâmetros e tratamento de outputs para métricas (incluindo tentativa de obter probabilidades/decision scores para ROC/PR)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff0b71d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff0b71d0",
        "outputId": "3380cd4f-6957-4e62-bbdc-88a624ba476e"
      },
      "outputs": [],
      "source": [
        "# Modelagem e avaliacao\n",
        "from sklearn.pipeline import Pipeline  # organiza vetorizador+classificador em um unico objeto\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # converte textos em features numéricas ponderadas\n",
        "from sklearn.linear_model import LogisticRegression  # baseline robusto para classificacao binaria/multiclasse\n",
        "from sklearn.naive_bayes import MultinomialNB  # bom para texto esparso e rápido\n",
        "from sklearn.svm import LinearSVC  # SVM linear eficiente para grandes features de texto\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score  # metricas e curvas\n",
        "\n",
        "# Preparamos X/y e removemos textos vazios — evita erros no vetorizador\n",
        "X_train = df_train_proc['text_lemmatized'].astype(str)\n",
        "y_train = df_train_proc['sentiment']\n",
        "X_val = df_val_proc['text_lemmatized'].astype(str)\n",
        "y_val = df_val_proc['sentiment']\n",
        "mask_train = X_train.str.strip().replace('', np.nan).notna()\n",
        "mask_val = X_val.str.strip().replace('', np.nan).notna()\n",
        "X_train = X_train[mask_train]; y_train = y_train[mask_train]\n",
        "X_val = X_val[mask_val]; y_val = y_val[mask_val]\n",
        "print(f'Treino: {len(X_train)} | Validation: {len(X_val)}')\n",
        "\n",
        "# Dicionario de modelos: facilidade para loop e comparacao\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=2000, random_state=42),\n",
        "    'MultinomialNB': MultinomialNB(),\n",
        "    'LinearSVC': LinearSVC(max_iter=20000, random_state=42)\n",
        "}\n",
        "results = {}\n",
        "for name, clf in models.items():\n",
        "    print(f'[MODEL] Treinando {name}...')\n",
        "    pipe = Pipeline([('tfidf', TfidfVectorizer(max_features=15000, ngram_range=(1,2))), ('clf', clf)])\n",
        "    t0 = time.time(); pipe.fit(X_train, y_train); t1 = time.time(); train_time = t1 - t0\n",
        "    t0p = time.time(); preds = pipe.predict(X_val); t1p = time.time(); predict_time = t1p - t0p\n",
        "    acc = accuracy_score(y_val, preds); f1 = f1_score(y_val, preds, average='macro')\n",
        "    report = classification_report(y_val, preds, output_dict=True)\n",
        "    cm = confusion_matrix(y_val, preds)\n",
        "    # Tentamos obter scores para ROC/PR: preferimos predict_proba (retorna a probabilidade de que uma amostra pertença a cada uma das classes disponíveis), senão usamos decision_function (indica a margem de confiança do modelo; quanto maior o valor absoluto, mais confiante o modelo está na sua classificação) quando disponivel\n",
        "    y_score = None\n",
        "    try:\n",
        "        y_score = pipe.predict_proba(X_val)\n",
        "    except Exception:\n",
        "        try:\n",
        "            decision = pipe.decision_function(X_val)\n",
        "            if decision.ndim == 1:\n",
        "                # transformar vetor 1D em array 2-colunas (negativo,positivo) para compatibilidade\n",
        "                decision = np.vstack([-decision, decision]).T\n",
        "            y_score = decision\n",
        "        except Exception:\n",
        "            y_score = None\n",
        "    results[name] = {\n",
        "        'pipeline': pipe, 'accuracy': acc, 'f1_macro': f1, 'train_time_seconds': train_time, 'predict_time_seconds': predict_time,\n",
        "        'report': report, 'confusion_matrix': cm.tolist(), 'y_score': y_score\n",
        "    }\n",
        "    print(f'[RESULT] {name} — Accuracy: {acc:.4f} | F1-macro: {f1:.4f}')\n",
        "\n",
        "# Escolher melhor por F1-macro (avalia o desempenho de modelos de classificação multiclasse) e salvar o pipeline final em disco (joblib)\n",
        "best = max(results.keys(), key=lambda k: results[k]['f1_macro'])\n",
        "best_pipeline = results[best]['pipeline']\n",
        "joblib.dump(best_pipeline, MODEL_PATH)\n",
        "print(f'[OK] Melhor modelo: {best} salvo em: {MODEL_PATH}')\n",
        "\n",
        "# Salvar metricas resumidas em JSON (util para dashboards/relatorios)\n",
        "metrics_out = {'best_model': best, 'results': {}}\n",
        "for k in results:\n",
        "    metrics_out['results'][k] = {\n",
        "        'accuracy': results[k]['accuracy'],\n",
        "        'f1_macro': results[k]['f1_macro'],\n",
        "        'train_time_seconds': results[k]['train_time_seconds'],\n",
        "        'predict_time_seconds': results[k]['predict_time_seconds'],\n",
        "        'classification_report': results[k]['report'],\n",
        "        'confusion_matrix': results[k]['confusion_matrix']\n",
        "    }\n",
        "with open(os.path.join(METRICS_DIR, 'model_metrics.json'), 'w') as f:\n",
        "    json.dump(metrics_out, f, indent=2)\n",
        "print('[OK] Metricas salvas em reports/metrics/model_metrics.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a11711",
      "metadata": {
        "id": "52a11711"
      },
      "source": [
        "---\n",
        "## 5. Visualizações Comparativas (ROC / PR / Confusion) <a id='visualizations'></a>\n",
        "\n",
        "Nesta seção geramos um ROC comparativo, um PR comparativo e um arquivo com todas as matrizes de confusão lado-a-lado. Cada bloco tenta usar `y_score` salvo nos resultados — se não houver score (por exemplo, MultinomialNB tem predict_proba, SVC pode não ter), os plots são pulados para esse modelo. A curva ROC (Receiver Operating Characteristic) mostra a relação entre taxa de verdadeiros positivos (coordenada y) e taxa de falsos positivos (coordenada x) ao variar o limiar — útil para comparar separabilidade do modelo; a curva Precision‑Recall (PR) mostra a troca de desempenho entre precisão e recall e costuma ser mais informativa quando as classes estão desbalanceadas (foca em quão bem o modelo encontra a classe positiva sem gerar muitos falsos positivos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae8d15f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cae8d15f",
        "outputId": "df4f9404-75de-4325-b04f-e004b78a81a1"
      },
      "outputs": [],
      "source": [
        "# Geracao de graficos comparativos\n",
        "classes_all = np.unique(y_val)\n",
        "try:\n",
        "    from sklearn.preprocessing import label_binarize\n",
        "    y_val_b_all = label_binarize(y_val, classes=classes_all)\n",
        "except Exception:\n",
        "    y_val_b_all = None\n",
        "\n",
        "# ROC comparativo — agregamos curvas quando temos scores multi-classe binarizados\n",
        "plt.figure(figsize=(8,6))\n",
        "plotted_any = False\n",
        "for name in results:\n",
        "    y_score = results[name].get('y_score')\n",
        "    if y_score is None or y_val_b_all is None:\n",
        "        continue\n",
        "    try:\n",
        "        fpr, tpr, _ = roc_curve(y_val_b_all.ravel(), y_score.ravel())\n",
        "        auc_val = None\n",
        "        try:\n",
        "            auc_val = roc_auc_score(y_val_b_all, y_score, average='macro', multi_class='ovr')\n",
        "        except Exception:\n",
        "            auc_val = None\n",
        "        label = f'{name}'\n",
        "        if auc_val is not None:\n",
        "            label += f' (AUC={auc_val:.3f})'\n",
        "        plt.plot(fpr, tpr, lw=2, label=label)\n",
        "        plotted_any = True\n",
        "    except Exception:\n",
        "        continue\n",
        "if plotted_any:\n",
        "    plt.plot([0,1],[0,1],'k--', linewidth=0.5)\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title('Comparative ROC Curves (all models)')\n",
        "    plt.legend(loc='lower right'); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(VIS_DIR, 'comparison_roc.png'))\n",
        "    plt.show()\n",
        "    print('[OK] ROC comparativo salvo')\n",
        "else:\n",
        "    print('[WARN] Nenhum score disponivel para plotting ROC comparativo')\n",
        "\n",
        "# PR comparativo\n",
        "plt.figure(figsize=(8,6))\n",
        "plotted_any = False\n",
        "for name in results:\n",
        "    y_score = results[name].get('y_score')\n",
        "    if y_score is None or y_val_b_all is None:\n",
        "        continue\n",
        "    try:\n",
        "        precision, recall, _ = precision_recall_curve(y_val_b_all.ravel(), y_score.ravel())\n",
        "        ap = None\n",
        "        try:\n",
        "            ap = average_precision_score(y_val_b_all, y_score, average='macro')\n",
        "        except Exception:\n",
        "            ap = None\n",
        "        label = f'{name}'\n",
        "        if ap is not None:\n",
        "            label += f' (AP={ap:.3f})'\n",
        "        plt.plot(recall, precision, lw=2, label=label)\n",
        "        plotted_any = True\n",
        "    except Exception:\n",
        "        continue\n",
        "if plotted_any:\n",
        "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
        "    plt.title('Comparative Precision-Recall Curves (all models)')\n",
        "    plt.legend(loc='lower left'); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(VIS_DIR, 'comparison_pr.png'))\n",
        "    plt.close()\n",
        "    print('[OK] PR comparativo salvo')\n",
        "else:\n",
        "    print('[WARN] Nenhum score disponivel para plotting PR comparativo')\n",
        "\n",
        "# Confusion matrices lado-a-lado (sempre disponiveis a partir das preds)\n",
        "model_names = list(results.keys())\n",
        "cms = [np.array(results[nm]['confusion_matrix']) for nm in model_names]\n",
        "if len(cms) > 0:\n",
        "    vmax = max(cm.max() for cm in cms)\n",
        "    fig, axes = plt.subplots(1, len(model_names), figsize=(6 * len(model_names), 5))\n",
        "    if len(model_names) == 1:\n",
        "        axes = [axes]\n",
        "    for ax, nm, cm in zip(axes, model_names, cms):\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes_all, yticklabels=classes_all, vmin=0, vmax=vmax, ax=ax)\n",
        "        ax.set_title(f'Confusion — {nm}'); ax.set_xlabel('Predito'); ax.set_ylabel('Real')\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(VIS_DIR, 'comparison_confusion_matrices.png'))\n",
        "    plt.close(); print('[OK] Matrizes de confusao comparativas salvas')\n",
        "else:\n",
        "    print('[WARN] Nenhuma matriz de confusao disponivel')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65875c50",
      "metadata": {
        "id": "65875c50"
      },
      "source": [
        "---\n",
        "## 6. Deploy com Docker (Opcional) <a id='deploy'></a>\n",
        "\n",
        "Gera um `Dockerfile` de exemplo em `src/api/Dockerfile` para empacotar a aplicação. Comentário no código explica cada instrução."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb5cfe48",
      "metadata": {
        "id": "fb5cfe48"
      },
      "outputs": [],
      "source": [
        "# Gerar Dockerfile de exemplo (opcional)\n",
        "# O Dockerfile básico instala dependências e expõe a porta do servidor\n",
        "dockerfile_content = '''\n",
        "FROM python:3.9-slim\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .  # copia manifest de dependencias\n",
        "RUN pip install --no-cache-dir -r requirements.txt  # instala dependencias no container\n",
        "COPY . .  # copia o codigo da aplicacao\n",
        "EXPOSE 8000  # expõe porta padrao da app\n",
        "CMD [\"python\", \"manage.py\", \"runserver\", \"0.0.0.0:8000\"]\n",
        "'''\n",
        "os.makedirs(os.path.join(BASE_DIR, 'src', 'api'), exist_ok=True)\n",
        "with open(os.path.join(BASE_DIR, 'src', 'api', 'Dockerfile'), 'w') as f:\n",
        "    f.write(dockerfile_content)\n",
        "print('[OK] Dockerfile criado (src/api/Dockerfile)')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "07be8a1f"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
