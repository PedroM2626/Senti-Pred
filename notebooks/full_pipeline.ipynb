{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTI-PRED: Pipeline Completo de Analise de Sentimentos\n",
    "## Autor: Pedro Morato Lahoz\n",
    "## Data: Outubro 2025\n",
    "\n",
    "---\n",
    "\n",
    "### Indice:\n",
    "1. [Configuracao Inicial](#config)\n",
    "2. [Analise Exploratoria (EDA)](#eda)\n",
    "3. [Pre-processamento](#preprocessing)\n",
    "4. [Modelagem](#modeling)\n",
    "5. [Avaliacao](#evaluation)\n",
    "6. [Deploy com Docker](#deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuracao Inicial <a id='config'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacoes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Configuracoes visuais\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style='whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"[OK] Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download recursos NLTK\n",
    "recursos = ['punkt', 'stopwords', 'wordnet', 'punkt_tab', 'rslp']\n",
    "for recurso in recursos:\n",
    "    nltk.download(recurso, quiet=True)\n",
    "\n",
    "print(\"[OK] Recursos NLTK baixados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar caminhos\n",
    "DATA_RAW = r'c:\\Users\\pedro\\Downloads\\Senti-Pred\\data\\raw\\Test.csv'\n",
    "DATA_PROCESSED = r'c:\\Users\\pedro\\Downloads\\Senti-Pred\\data\\processed\\processed_data.csv'\n",
    "MODEL_PATH = r'c:\\Users\\pedro\\Downloads\\Senti-Pred\\src\\models\\sentiment_model.pkl'\n",
    "\n",
    "# Criar diretorios se nao existirem\n",
    "os.makedirs(os.path.dirname(DATA_PROCESSED), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "os.makedirs('../reports/visualizacoes', exist_ok=True)\n",
    "\n",
    "print(\"[OK] Estrutura de diretorios configurada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Analise Exploratoria de Dados (EDA) <a id='eda'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "print(\"Carregando dados...\")\n",
    "df = pd.read_csv(DATA_RAW)\n",
    "print(f\"[OK] Dados carregados: {df.shape[0]} registros e {df.shape[1]} colunas\")\n",
    "\n",
    "# Exibir primeiras linhas\n",
    "print(\"\\nPrimeiras linhas do dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Informações básicas\n",
    "print(\"\\nInformações do dataset:\")\n",
    "df.info()\n",
    "\n",
    "# Estatísticas descritivas\n",
    "print(\"\\nEstatísticas descritivas:\")\n",
    "display(df.describe(include='all'))\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\nValores nulos por coluna:\")\n",
    "display(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição de classes (assumindo que a coluna de sentimento é 'sentiment')\n",
    "if 'sentiment' in df.columns:\n",
    "    print(\"\\nDistribuição de classes:\")\n",
    "    sentiment_counts = df['sentiment'].value_counts()\n",
    "    display(sentiment_counts)\n",
    "    \n",
    "    # Visualizar distribuição\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='sentiment', data=df)\n",
    "    plt.title('Distribuição de Sentimentos')\n",
    "    plt.xlabel('Sentimento')\n",
    "    plt.ylabel('Contagem')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    # Se não houver coluna 'sentiment', assumir que a última coluna é a target\n",
    "    target_col = df.columns[-1]\n",
    "    print(f\"\\nDistribuição de classes (coluna {target_col}):\")\n",
    "    target_counts = df[target_col].value_counts()\n",
    "    display(target_counts)\n",
    "    \n",
    "    # Visualizar distribuição\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x=target_col, data=df)\n",
    "    plt.title(f'Distribuição de {target_col}')\n",
    "    plt.xlabel(target_col)\n",
    "    plt.ylabel('Contagem')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de comprimento de texto\n",
    "print(\"\\nAnálise de comprimento de texto:\")\n",
    "# Identificar a coluna de texto (assumindo que é a primeira coluna ou se chama 'text')\n",
    "text_col = 'text' if 'text' in df.columns else df.columns[0]\n",
    "\n",
    "df['text_length'] = df[text_col].apply(lambda x: len(str(x).split()))\n",
    "print(f\"Comprimento médio: {df['text_length'].mean():.2f} palavras\")\n",
    "print(f\"Comprimento mínimo: {df['text_length'].min()} palavras\")\n",
    "print(f\"Comprimento máximo: {df['text_length'].max()} palavras\")\n",
    "\n",
    "# Visualizar distribuição de comprimento\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['text_length'], bins=50, kde=True)\n",
    "plt.title('Distribuição de Comprimento de Texto')\n",
    "plt.xlabel('Número de Palavras')\n",
    "plt.ylabel('Frequência')\n",
    "plt.axvline(df['text_length'].mean(), color='red', linestyle='--', label=f'Média: {df[\"text_length\"].mean():.2f}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/visualizacoes/text_lenght.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras mais comuns\n",
    "print(\"\\nPalavras mais comuns:\")\n",
    "all_words = ' '.join(df[text_col].astype(str)).lower().split()\n",
    "word_counts = pd.Series(all_words).value_counts()\n",
    "print(word_counts.head(20))\n",
    "\n",
    "# Visualizar palavras mais comuns\n",
    "plt.figure(figsize=(12, 6))\n",
    "word_counts[:20].plot(kind='bar')\n",
    "plt.title('20 Palavras Mais Frequentes')\n",
    "plt.xlabel('Palavra')\n",
    "plt.ylabel('Frequência')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/visualizacoes/number_words.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"[OK] Análise exploratória concluída!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Pre-processamento <a id='preprocessing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir funções de pré-processamento\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Limpa o texto removendo URLs, menções, pontuações e números\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Remove stopwords do texto\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    tokens = word_tokenize(text, language='portuguese')\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Lematiza o texto\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text, language='portuguese')\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "print(\"[OK] Funções de pré-processamento definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar pré-processamento\n",
    "print(\"Aplicando pré-processamento...\")\n",
    "\n",
    "# Identificar colunas\n",
    "text_col = 'text' if 'text' in df.columns else df.columns[0]\n",
    "target_col = 'sentiment' if 'sentiment' in df.columns else df.columns[-1]\n",
    "\n",
    "# Criar cópia para processamento\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Aplicar etapas de pré-processamento\n",
    "print(\"1. Limpando textos...\")\n",
    "df_processed['text_clean'] = df_processed[text_col].apply(clean_text)\n",
    "\n",
    "print(\"2. Removendo stopwords...\")\n",
    "df_processed['text_no_stop'] = df_processed['text_clean'].apply(remove_stopwords)\n",
    "\n",
    "print(\"3. Lematizando textos...\")\n",
    "df_processed['text_lemmatized'] = df_processed['text_no_stop'].apply(lemmatize_text)\n",
    "\n",
    "# Exibir exemplos\n",
    "print(\"\\nExemplos de textos processados:\")\n",
    "examples = pd.DataFrame({\n",
    "    'Original': df_processed[text_col].head(3),\n",
    "    'Limpo': df_processed['text_clean'].head(3),\n",
    "    'Sem Stopwords': df_processed['text_no_stop'].head(3),\n",
    "    'Lematizado': df_processed['text_lemmatized'].head(3)\n",
    "})\n",
    "display(examples)\n",
    "\n",
    "# Salvar dados processados\n",
    "df_processed.to_csv(DATA_PROCESSED, index=False)\n",
    "print(f\"[OK] Dados processados salvos em: {DATA_PROCESSED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Modelagem <a id='modeling'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para modelagem\n",
    "print(\"Preparando dados para modelagem...\")\n",
    "\n",
    "# Definir features e target\n",
    "X = df_processed['text_lemmatized']\n",
    "y = df_processed[target_col]\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Dados de treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"Dados de teste: {X_test.shape[0]} amostras\")\n",
    "\n",
    "# Verificar distribuição nos conjuntos\n",
    "print(\"\\nDistribuição de classes:\")\n",
    "print(f\"Treino:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\nTeste:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir e treinar modelos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TREINAMENTO DE MODELOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definir modelos a serem testados\n",
    "models_config = {\n",
    "    'Regressão Logística': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Dicionário para armazenar resultados\n",
    "models = {}\n",
    "\n",
    "# Treinar e avaliar cada modelo\n",
    "for name, model in models_config.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    \n",
    "    # Criar pipeline com vetorização TF-IDF\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Treinar\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predizer\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Avaliar\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Acurácia: {accuracy:.4f}\")\n",
    "    \n",
    "    # Salvar modelo e predições\n",
    "    models[name] = (pipeline, y_pred, accuracy)\n",
    "    \n",
    "    # Exibir matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=pipeline.classes_, \n",
    "                yticklabels=pipeline.classes_)\n",
    "    plt.title(f'Matriz de Confusão - {name}')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Real')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../reports/visualizacoes/{name.lower().replace(\" \", \"-\")}_matriz.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Exibir relatório de classificação\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Identificar melhor modelo\n",
    "best_model_name = max(models, key=lambda k: models[k][2])\n",
    "best_model = models[best_model_name][0]\n",
    "best_accuracy = models[best_model_name][2]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"MELHOR MODELO: {best_model_name} (Acurácia: {best_accuracy:.4f})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar modelos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARAÇÃO DE MODELOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extrair acurácias\n",
    "model_names = list(models.keys())\n",
    "accuracies = [models[name][2] for name in model_names]\n",
    "\n",
    "# Visualizar comparação\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(model_names, accuracies, color=['blue', 'green', 'purple'])\n",
    "plt.title('Comparação de Acurácia entre Modelos')\n",
    "plt.xlabel('Modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/visualizacoes/models_comparasion.png')\n",
    "plt.show()\n",
    "\n",
    "# Salvar melhor modelo\n",
    "print(f\"\\nSalvando melhor modelo ({best_model_name})...\")\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "\n",
    "# Salvar informações do modelo\n",
    "info_path = os.path.join(os.path.dirname(MODEL_PATH), 'model_info.txt')\n",
    "with open(info_path, 'w') as f:\n",
    "    f.write(f\"Modelo: {best_model_name}\\n\")\n",
    "    f.write(f\"Acurácia: {best_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Data de treinamento: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "    f.write(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\\n\")\n",
    "    f.write(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\\n\")\n",
    "    \n",
    "    # Adicionar relatório de classificação\n",
    "    f.write(\"\\nRelatório de Classificação:\\n\")\n",
    "    f.write(classification_report(y_test, models[best_model_name][1]))\n",
    "\n",
    "print(f\"[OK] Modelo salvo em: {MODEL_PATH}\")\n",
    "print(f\"[OK] Informações salvas em: {info_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Avaliacao Detalhada <a id='evaluation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analise de erros\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALISE DE ERROS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred_best = models[best_model_name][1]\n",
    "\n",
    "# Identificar erros\n",
    "errors = y_test != y_pred_best\n",
    "error_indices = np.where(errors)[0]\n",
    "\n",
    "error_df = pd.DataFrame({\n",
    "    'Texto': X_test.iloc[error_indices].values,\n",
    "    'Real': y_test.iloc[error_indices].values,\n",
    "    'Predito': y_pred_best[error_indices]\n",
    "})\n",
    "\n",
    "print(f\"\\nTotal de erros: {len(error_indices)} ({len(error_indices)/len(y_test)*100:.2f}%)\")\n",
    "print(f\"Total de acertos: {len(y_test) - len(error_indices)} ({(1 - len(error_indices)/len(y_test))*100:.2f}%)\")\n",
    "\n",
    "if len(error_indices) > 0:\n",
    "    print(\"\\nExemplos de erros:\")\n",
    "    display(error_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliacao por comprimento de texto\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AVALIACAO POR COMPRIMENTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular comprimento dos textos de teste\n",
    "text_lengths = X_test.apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Categorizar\n",
    "bins = [0, 5, 10, 20, float('inf')]\n",
    "labels = ['Muito Curto', 'Curto', 'Medio', 'Longo']\n",
    "length_categories = pd.cut(text_lengths, bins=bins, labels=labels)\n",
    "\n",
    "# Calcular acuracia por categoria\n",
    "accuracy_by_length = {}\n",
    "for category in labels:\n",
    "    mask = length_categories == category\n",
    "    if mask.sum() > 0:\n",
    "        acc = accuracy_score(y_test[mask], y_pred_best[mask])\n",
    "        accuracy_by_length[category] = acc\n",
    "        print(f\"   {category:15s}: {acc:.4f} ({mask.sum()} textos)\")\n",
    "\n",
    "# Visualizar\n",
    "if accuracy_by_length:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(accuracy_by_length.keys(), accuracy_by_length.values(), color='purple')\n",
    "    plt.title('Acuracia por Comprimento de Texto')\n",
    "    plt.xlabel('Categoria')\n",
    "    plt.ylabel('Acuracia')\n",
    "    plt.ylim(0, 1)\n",
    "    for i, (cat, acc) in enumerate(accuracy_by_length.items()):\n",
    "        plt.text(i, acc + 0.02, f\"{acc:.3f}\", ha='center', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/visualizacoes/precision.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas ROC (se aplicavel)\n",
    "if len(best_model.classes_) == 2 and hasattr(best_model, 'predict_proba'):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CURVAS ROC E PRECISION-RECALL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Curva ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob, pos_label=best_model.classes_[1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    axes[0].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                 label=f'ROC (AUC = {roc_auc:.2f})')\n",
    "    axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    axes[0].set_xlim([0.0, 1.0])\n",
    "    axes[0].set_ylim([0.0, 1.05])\n",
    "    axes[0].set_xlabel('Taxa de Falsos Positivos')\n",
    "    axes[0].set_ylabel('Taxa de Verdadeiros Positivos')\n",
    "    axes[0].set_title('Curva ROC')\n",
    "    axes[0].legend(loc=\"lower right\")\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Curva Precision-Recall\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob, pos_label=best_model.classes_[1])\n",
    "    \n",
    "    axes[1].plot(recall, precision, color='green', lw=2)\n",
    "    axes[1].set_xlabel('Recall')\n",
    "    axes[1].set_ylabel('Precision')\n",
    "    axes[1].set_title('Curva Precision-Recall')\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n[OK] AUC-ROC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao de predicao\n",
    "def predict_sentiment(text, model=best_model):\n",
    "    \"\"\"\n",
    "    Prediz sentimento de um texto\n",
    "    \n",
    "    Args:\n",
    "        text (str): Texto para analise\n",
    "        model: Modelo treinado\n",
    "    \n",
    "    Returns:\n",
    "        dict: Resultado com sentimento e confianca\n",
    "    \"\"\"\n",
    "    # Pre-processar\n",
    "    text_clean = clean_text(text)\n",
    "    text_no_stop = remove_stopwords(text_clean)\n",
    "    text_lem = lemmatize_text(text_no_stop)\n",
    "    \n",
    "    # Predizer\n",
    "    sentiment = model.predict([text_lem])[0]\n",
    "    \n",
    "    # Confianca\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probs = model.predict_proba([text_lem])[0]\n",
    "        confidence = max(probs)\n",
    "    else:\n",
    "        confidence = 1.0\n",
    "    \n",
    "    return {\n",
    "        'texto_original': text,\n",
    "        'texto_processado': text_lem,\n",
    "        'sentimento': sentiment,\n",
    "        'confianca': confidence\n",
    "    }\n",
    "\n",
    "print(\"[OK] Funcao de predicao criada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar com exemplos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTES COM EXEMPLOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_examples = [\n",
    "    \"Este produto e excelente! Recomendo muito!\",\n",
    "    \"Pessima qualidade. Nao comprem.\",\n",
    "    \"E okay, nada de especial.\",\n",
    "    \"Adorei! Muito bom mesmo!\",\n",
    "    \"Terrivel. Pior compra da minha vida.\"\n",
    "]\n",
    "\n",
    "for text in test_examples:\n",
    "    result = predict_sentiment(text)\n",
    "    \n",
    "    print(f\"\\nTexto: {result['texto_original']}\")\n",
    "    print(f\"   Sentimento: {result['sentimento'].upper()}\")\n",
    "    print(f\"   Confianca: {result['confianca']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Deploy com Docker <a id='deploy'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrutura de arquivos para deploy:\n",
    "\n",
    "```\n",
    "Senti-Pred/\n",
    "├── app.py                 # API Flask\n",
    "├── requirements.txt       # Dependencias\n",
    "├── Dockerfile            # Configuracao Docker\n",
    "├── docker-compose.yml    # Orquestracao\n",
    "└── src/\n",
    "    └── models/\n",
    "        └── sentiment_model.pkl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar arquivo app.py (API Flask)\n",
    "app_code = '''\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download recursos NLTK\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Carregar modelo\n",
    "model = joblib.load('src/models/sentiment_model.pkl')\n",
    "\n",
    "# Funcoes de pre-processamento\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\\\S+|www\\\\S+|https\\\\S+', '', text)\n",
    "    text = re.sub(r'@\\\\w+|#\\\\w+', '', text)\n",
    "    text = re.sub(r'[^\\\\w\\\\s]', '', text)\n",
    "    text = re.sub(r'\\\\d+', '', text)\n",
    "    text = re.sub(r'\\\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    tokens = word_tokenize(text, language='portuguese')\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text, language='portuguese')\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "def preprocess(text):\n",
    "    text = clean_text(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize_text(text)\n",
    "    return text\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return jsonify({\n",
    "        'message': 'Senti-Pred API',\n",
    "        'version': '1.0',\n",
    "        'endpoints': {\n",
    "            '/predict': 'POST - Analise de sentimento',\n",
    "            '/health': 'GET - Status da API'\n",
    "        }\n",
    "    })\n",
    "\n",
    "@app.route('/health')\n",
    "def health():\n",
    "    return jsonify({'status': 'healthy'})\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        \n",
    "        if not data or 'text' not in data:\n",
    "            return jsonify({'error': 'Texto nao fornecido'}), 400\n",
    "        \n",
    "        text = data['text']\n",
    "        \n",
    "        # Pre-processar\n",
    "        text_processed = preprocess(text)\n",
    "        \n",
    "        # Predizer\n",
    "        sentiment = model.predict([text_processed])[0]\n",
    "        \n",
    "        # Confianca\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            probs = model.predict_proba([text_processed])[0]\n",
    "            confidence = float(max(probs))\n",
    "        else:\n",
    "            confidence = 1.0\n",
    "        \n",
    "        return jsonify({\n",
    "            'text': text,\n",
    "            'sentiment': sentiment,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)\n",
    "'''\n",
    "\n",
    "# Salvar app.py\n",
    "app_path = r'c:\\Users\\pedro\\Downloads\\Senti-Pred\\app.py'\n",
    "with open(app_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(app_code)\n",
    "\n",
    "print(f\"[OK] app.py criado em: {app_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar requirements.txt\n",
    "requirements = '''\n",
    "flask==3.0.0\n",
    "scikit-learn==1.3.0\n",
    "pandas==2.1.0\n",
    "numpy==1.25.0\n",
    "joblib==1.3.2\n",
    "nltk==3.8.1\n",
    "gunicorn==21.2.0\n",
    "'''\n",
    "\n",
    "req_path = r'c:\\Users\\pedro\\Downloads\\Senti-Pred\\requirements.txt'\n",
    "with open(req_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(requirements.strip())\n",
    "\n",
    "print(f\"[OK] requirements.txt criado em: {req_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar Dockerfile\n",
    "dockerfile = '''\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar arquivos\n",
    "COPY requirements.txt .\n",
    "COPY app.py .\n",
    "COPY src/ ./src/\n",
    "\n",
    "# Instalar dependencias\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Download recursos NLTK\n",
    "RUN python -c \"import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('punkt_tab')\"\n",
    "\n",
    "# Expor porta\n",
    "EXPOSE 5000\n",
    "\n",
    "# Comando de execucao\n",
    "CMD [\"gunicorn\", \"--bind\", \"0.0.0.0:5000\", \"--workers\", \"4\", \"app:app\"]\n",
    "'''\n",
    "\n",
    "dockerfile_path = r'c:\\Users\\pedro\\Downloads\\Senti-Pred\\Dockerfile'\n",
    "with open(dockerfile_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(dockerfile.strip())\n",
    "\n",
    "print(f\"[OK] Dockerfile criado em: {dockerfile_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar docker-compose.yml\n",
    "docker_compose = '''\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  senti-pred-api:\n",
    "    build: .\n",
    "    container_name: senti-pred\n",
    "    ports:\n",
    "      - \"5000:5000\"\n",
    "    environment:\n",
    "      - FLASK_ENV=production\n",
    "    restart: unless-stopped\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:5000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "'''\n",
    "\n",
    "compose_path = r'c:\\Users\\pedro\\Downloads\\Senti-Pred\\docker-compose.yml'\n",
    "with open(compose_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(docker_compose.strip())\n",
    "\n",
    "print(f\"[OK] docker-compose.yml criado em: {compose_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comandos para Deploy:\n",
    "\n",
    "```bash\n",
    "# 1. Navegar ate o diretorio do projeto\n",
    "cd c:\\Users\\pedro\\Downloads\\Senti-Pred\n",
    "\n",
    "# 2. Build e iniciar containers\n",
    "docker-compose up --build -d\n",
    "\n",
    "# 3. Verificar status\n",
    "docker-compose ps\n",
    "\n",
    "# 4. Ver logs\n",
    "docker-compose logs -f\n",
    "\n",
    "# 5. Testar API\n",
    "curl -X POST http://localhost:5000/predict \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"text\": \"Este produto e excelente!\"}'\n",
    "\n",
    "# 6. Parar containers\n",
    "docker-compose down\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar script de teste da API\n",
    "test_script = '''\n",
    "import requests\n",
    "import json\n",
    "\n",
    "API_URL = \"http://localhost:5000\"\n",
    "\n",
    "def test_health():\n",
    "    \"\"\"Testa endpoint de health\"\"\"\n",
    "    response = requests.get(f\"{API_URL}/health\")\n",
    "    print(f\"Health Check: {response.json()}\")\n",
    "\n",
    "def test_predict(text):\n",
    "    \"\"\"Testa predicao de sentimento\"\"\"\n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/predict\",\n",
    "        json={\"text\": text}\n",
    "    )\n",
    "    result = response.json()\n",
    "    print(f\"\\\\nTexto: {text}\")\n",
    "    print(f\"Sentimento: {result.get('sentiment')}\")\n",
    "    print(f\"Confianca: {result.get('confidence', 0):.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Testar health\n",
    "    test_health()\n",
    "    \n",
    "    # Testar predicoes\n",
    "    examples = [\n",
    "        \"Este produto e excelente! Recomendo!\",\n",
    "        \"Pessima qualidade. Nao comprem.\",\n",
    "        \"E okay, nada demais.\"\n",
    "    ]\n",
    "    \n",
    "    for text in examples:\n",
    "        test_predict(text)\n",
    "'''\n",
    "\n",
    "test_path = r'c:\\Users\\pedro\\Downloads\\Senti-Pred\\test_api.py'\n",
    "with open(test_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(test_script.strip())\n",
    "\n",
    "print(f\"[OK] test_api.py criado em: {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrucoes finais de deploy:\n",
    "\n",
    "1. **Certifique-se que o Docker esta instalado e rodando**\n",
    "\n",
    "2. **Execute no terminal:**\n",
    "   ```bash\n",
    "   docker-compose up --build -d\n",
    "   ```\n",
    "\n",
    "3. **API estara disponivel em:** `http://localhost:5000`\n",
    "\n",
    "4. **Para testar a API:**\n",
    "   ```bash\n",
    "   python test_api.py\n",
    "   ```\n",
    "\n",
    "5. **Para parar os containers:**\n",
    "   ```bash\n",
    "   docker-compose down\n",
    "   ```\n",
    "\n",
    "### Exemplo de uso da API:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# Analisar sentimento\n",
    "response = requests.post(\n",
    "    \"http://localhost:5000/predict\",\n",
    "    json={\"text\": \"Este produto é excelente!\"}\n",
    ")\n",
    "\n",
    "# Exibir resultado\n",
    "print(response.json())\n",
    "```\n",
    "\n",
    "### Conclusão\n",
    "\n",
    "Neste notebook, implementamos um pipeline completo de análise de sentimentos, desde o pré-processamento dos dados até o deploy da solução em um container Docker. O modelo treinado pode ser utilizado para classificar textos em português de acordo com o sentimento expresso.\n",
    "\n",
    "O pipeline inclui:\n",
    "1. Análise exploratória dos dados\n",
    "2. Pré-processamento de texto\n",
    "3. Treinamento e comparação de modelos\n",
    "4. Avaliação detalhada do melhor modelo\n",
    "5. Deploy da solução como API REST\n",
    "\n",
    "Para melhorias futuras, podemos considerar:\n",
    "- Utilizar modelos mais avançados como BERT ou transformers\n",
    "- Implementar técnicas de data augmentation\n",
    "- Adicionar mais métricas de avaliação\n",
    "- Implementar monitoramento da API em produção"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}